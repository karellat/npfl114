# Motivační přednáška 
* zápočet a zkouška
# Cvičení 
* 2-3 úkoly týdně
* 14 dní na úkol
* soutěžní úkoly 
* vylepšovat slidy z přednášky 

# Písemně ústní zkouška
* 100 bodů do zkoušky z úkolů 40 bodů 
* Deep Learning book -  https://www.deeplearningbook.org/
* 

# Opakování statistiky 
* hustota, distribuční funkce, 
* střední hodnota, variance
* Distribuce: 
    * Bernoulliho 
    * Kategoricka
* Self Information: 
    * amount of suprise when a random variable is sampled.
        * should be zero for events with probability 1 
        *  less likely events are more suprising
        * Independend events should have additive information 
            * $I(x) =^{def} -log(P(x)) = \frac{1}{P(x)}$
* Entropy 
    * amount of suprise in the whole distribution
    * nejmenší možné binární zakodování informace dané distribucí(Huffman)

* Cross-Entropy
    * amount of suprise given more than one distribution
    * míra podobností dvou distribucí 
* Kullback-Leibler Divergence (KL Divergence)
    * relative entropy 

* Normal Distribution 
    * Why?
        * CLT - central limit theorem
        * Principle of Maximum Entropy 

* Machine Learning 
    * **Mitchell** 
    * A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its perfomance at tasks in T, as measured by P, improves with experience E. 

    * Task T 
        * classification 
        * regression 
        * structured prediction, denoising, density estimation 
    * Experience E 
        * supervised
        * unsupervised
        * reinforcement learning, semi-supervised learning 
    * Measure P 
        * accuracy, error rate, F-score

* Historie 
    * nelinearita 
        * 